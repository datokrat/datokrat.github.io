In this article I describe a fascinating connection between [[shallowly linearly independent sets|toggle:sli]]
and [[linear codes|toggle:linear codes]].

_ sli
    Two years ago, my friend Kolja stated an interesting problem. Let $V \coloneqq \mathbb{F}_2^n$ be the vector space of 
    binary words of length $n$. For $k\in \mathbb{N}$, how large a subset $M \subseteq \mathbb{F}_2^n$ can we find such
    that every subset $A\subseteq M$ of size $\le k$ is linearly independent?
    
    I have investigated this problem in a [[writeup|https://github.com/datokrat/shallow-linear-independence/blob/master/lokal-linear-unabh%C3%A4ngig.pdf]] in German and propose to call such sets shallowly linearly independent or, more specific, linearly $k$-independent.

_ linear codes
    A linear code is a concept from computer science. It is a linear subspace $M \subseteq \mathbb{F}_2^n$ of so-called codewords (adding two words means xor-ing them). $M$ is isomorphic to the vector space $\mathbb{F}_2^{\dim M}$, and that's why a linear code $M$ can be used to represent binary words of length $\dim M$. Although the encoded words might be longer, some codes have interesting error-correction properties, and that's the technology we all know from barcodes and CR codes.

The central observation is that while linear independence means that there are no non-trivial linear combinations of the zero vector, liner $k$-independence means that there are no non-trivial linear combinations with at most $k$ vectors involved. It is easier to see what is going on after formalizing this relationship a bit. Given $M \subseteq \mathbb{F}_2^n$, write all vectors of $M$ into the columns of a large matrix $A_M$ with dimensions $n\times \#M$. Feel free to explore an [[example|toggle:matrix example]].

_ matrix example
    Consider, for example, $$M = \{ 1000, 0100, 0010, 0001, 1111 \}.$$
    Then $$A_M = \begin{pmatrix} 1 & 0 & 0 & 0 & 1 \\ 0 & 1 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 & 1 \\ 0 & 0 & 0 & 1 & 1 \end{pmatrix}.$$

Now, linear combinations of zero are exactly those $v \in \mathbb{F}_2^{\# M}$ with $A_Mv = 0$, and the number of ones in $v$ (the Hamming weight) equals the number of vectors involved in the linear combination ([[example|toggle:linear combination example]]).

_ linear combination example
    In the example above, the smallest nontrivial linear combination of zero is $$ 1000 + 0100 + 0010 + 0001 + 1111 = 0.$$
    This linear combination is represented by the vector $ 11111 $, and the fact that it is a linear combination of zero
    can be expressed as $$ \begin{pmatrix} 1 & 0 & 0 & 0 & 1 \\ 0 & 1 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 & 1 \\ 0 & 0 & 0 & 1 & 1 \end{pmatrix} \begin{pmatrix} 1 \\ 1 \\ 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}.$$

In other words, the set of linear combinations of zero in M equals the kernel of $A_M$, and by the dimension formula, we obtain
$$ \dim \left<M\right> + \dim \ker A_M = \# M. $$

# Reversing the problem

A variant of the linear $k$-independence problem is: Given $n, l\in\mathbb{N}$, does a linearly $k$-independent set $M \le \mathbb{F}_2^n$ with $\lvert M \rvert = l$ exist?

In this case, $N\coloneqq\ker A_M \le \mathbb{F}_2^l$ would be a vector space with at least [[Hamming distance|toggle:Hamming distance]] $k+1$, with $\dim N \ge l - n$.
_ Hamming distance
    The Hamming distance of two binary vectors is the number of components in which they differ.
    The Hamming distance of a vector space (such as $N$) is the minimal Hamming distance between two distinct vectors.
    Because the Hamming distance is translation invariant, it suffices in this case to check the Hamming distances
    of the nonzero vectors to the zero vector. In this case, the Hamming distance between $w$ and $0$ is the so-called
    Hamming weight of $w$: the number of $1$'s of $w$.
    
    So, $N$ has at least Hamming distance $k+1$ if and only if there is no $w\in N \setminus \{0\}$ with at most $k$ occurrences of $1$.

Can we turn this observation around? That is, can we reconstruct such an $M$ from a vector space $N \le \mathbb{F}_2^l$ of dimension $l - n$ with at least Hamming distance $k+1$? The answer is yes ([[why?|toggle:why yes]]).

_ why yes
    You can reconstruct $M$ as follows.
    
    Find a basis of $B$ of the $N^\perp$, the orthogonal complement of $N$ in $\mathbb{F}_2^l$.
    $B$ contains exactly $l - n$ vectors.
    
    Observe that if you write these vectors into the rows of a $(l - n) \times l$ matrix $A$,
    the space $N$ is a subset of $\ker A$. Furthermore, because $\left(N^\perp\right)^\perp = N$,
    we even get $N = \ker A$.
    
    In other words, $N$ contains exactly the zero linear combinations of the rows of $A$.
    Because $N$ has at least Hamming distance $k+1$, this means that the rows of $A$ linearly $k$-independent.

Therefore, the problem can be reformulated in a form that may be familiar to many computer scientists. The vector space $N$ is a linear code [[(as described at the beginning)|toggle:linear codes]] with words of length $l$ and $l - n$ bits of information (that is, $n$ redundant bits).

# Linear codes that help

There are several well-known linear codes. The most popular code is probably the Hamming code, which has a word length of $2^m - 1$ and $m$ redundant bits ([[example|toggle:Hamming code example]]) and a Hamming distance of $3$.

_ Hamming code example
    Take a look at the $(7, 4)$-Hamming code (word length $7$ and $4$ bits of information):
    
    We index the bits of the $7$-bit codeword as $7654321$. Using this convention, all bits at a power-of-two index (1, 2, 4)
    will be parity bits and the remaining four (3, 5, 6, 7) are used to store the information.
    
    The parity bits are assigned in a way such that the binary number composed of positions $421$ is the index of a possible single-bit error that
    might occur when the codeword is transferred. For example, the bit at position 1 is the parity over all odd positions, while
    the bit at position 2 is the parity over all positions whose second-lowest bit is one.
    
    For example, $1100$ is encoded as $1100011$.

Thus, Hamming codes tell us something about linearly $2$-independent sets, which are [[utterly uninteresting|toggle:why uninteresting]]. But by adding an additional global parity bit, the Hamming code turns into a so-called SECDED code with a word length of $2^m$ and $m+1$ redundant bits and a Hamming distance of $4$ ([[example|toggle:SECDED example]]). SECDED codes thus lead to linearly $3$-independent sets with $\lvert M \rvert = 2^m$ and $n = m+1$. That is, $M$ contains half of all vectors of $\mathbb{F}_2^{m+1}$. I have [[shown|https://github.com/datokrat/shallow-linear-independence/blob/master/lokal-linear-unabh%C3%A4ngig.pdf]] that this is an optimal solution for $k = 3$.

_ why uninteresting
    Every set that does not contain zero is linearly $2$-independent.

_ SECDED example
    If $abcdefg$ is a Hamming codeword, then we can produce a corresponding SECDED codeword by
    introducing an additional bit $h$ which is the parity over all other bits.
    
    For example, $1100$ is encoded as $11000110$.

As predicted by the "theorem on the preservation of difficulty", as one of my lecturers has called it, it stays difficult to find optimal solutions in the case $k=4$. However, other well-known linear codes help to find good approximations to the problem. For example, [[Chen|https://doi.org/10.1109/18.133262]] claims that there are so-called BCH codes of Hamming distance $5$, word length $2^m - 1$ and $2m$ redundant bits. Translated into the language of shallow linear independence: There are at least $2^m - 1$ linearly $4$-independent vectors in $\mathbb{F}_2^{2m}$.

This is by far a better lower bound than those which I have found before.

